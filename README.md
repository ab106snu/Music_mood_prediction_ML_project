# Music_mood_prediction_ML_project
Today, music is a very important and perhaps inseparable part of people's daily life. There 
are many genres of music, and these genres are different from each other, resulting in 
people having different preferences of music.
our project is concerned with studying the available historical music data and predict the mood of the music.

# Data Description: 
Having data as a part of a project is one of the most vital things necessary for the execution 
of the project and to satisfy the objectives as well. Having said that, we have gathered the 
data on which we will be relying on while using our data set to achieve the set goal in our 
project. Given below are the understanding points for our data:
1. Acousticness: To determine whether the track is acoustic, a confidence measure from 0.0 
to 1.0 is set up. 1.0 is equivalent to high confidence that the track is acoustic. 
2. Danceability: This characteristic is responsible for determining the suitability for a track for 
dancing based on a combination of musical elements including tempo, rhythm stability, beat 
strength, and overall regularity. If there is a value of 0.0, that is indicative of least danceable, 
whereas a value of 1.0 is indicative of most danceable. 
3. Energy: This quantity is measured from 0.0 to 1.0. It is representative of a perceptual 
measure of intensity and activity. Perceptual features such as dynamic range, perceived 
loudness, timbre, onset rate, and general entropy play the role of attributing to the volatile 
nature of the energy tracks.
4. Instrumentalness: It is indicative of determining whether a track contains vocals or not. 
“Ooh” and “aah” sounds are treated as instrumental in this context. The more the value is 
inclined towards 1.0, the more possibility is that the track contains no vocal content. Values 
above 0.5 are indicative of instrumental tracks, but the confidence is higher as the value 
approaches 1.0.
5. Liveness: It determines whether the audience is present in the recording or not. A greater 
value of liveness represents an increased probability that the track was performed live. If a 
value exceeds 0.8, it is very likely that the track is performed live.
6. Loudness: This is indicative of the overall loudness of a track measured in decibels (dB). 
Loudness values are useful for comparing the relative loudness of tracks. Loudness is the 
quality of a sound that is the primary psychological correlate of physical strength (amplitude). 
Values typically range between -60 to 0 dB.
7. Speechiness: It is responsible for detecting the presence of spoken words in a track. The 
more exclusive is the speech-like recording, the closer to 1.0 the attribute value. For the 
values above 0.66, they are indicative that they are probably made entirely of spoken words. 
Values that are between 0.33 and 0.66 are indicative of the fact that they may contain both 
music and speech. For the values below 0.33 are most likely representative of music and other 
non-speech-like tracks. 
8. Valence: It is measured from 0.0 to 1.0 which is indicative of the musical positiveness 
conveyed by a track. Tracks with high valence sound more positive (e.g., happy, cheerful, 
euphoric), while tracks with low valence sound more negative (e.g., sad, depressed, angry). 
9. Tempo: The overall estimated tempo of a track in beats per minute (BPM). In musical 
terminology, the tempo is the speed or pace of a given piece and derives directly from the 
average beat duration

# Algorithms:

1.Logistic Regression
2.Support vector machine
3.KNN Model
